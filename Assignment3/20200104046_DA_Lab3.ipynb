{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFVMIRLuAOIi",
        "outputId": "0214bfcf-96e6-43e3-e946-b11aaeaaa46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.0.3-bin-hadoop3.2/python/pyspark/sql/session.py:381: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
            "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Install Spark (change the version number if needed)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop3.2.tgz\n",
        "\n",
        "# Unzip the Spark file to the current folder\n",
        "!tar xf spark-3.0.3-bin-hadoop3.2.tgz\n",
        "\n",
        "# Install findspark\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop3.2\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# Test Spark\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('/Social_Network_Ads.csv',header=True,escape=\"\\\"\")"
      ],
      "metadata": {
        "id": "YZtJqbtuA3_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType,BooleanType,DateType, DoubleType\n",
        "df=df.withColumn(\"Age\",df.Age.cast(IntegerType()))"
      ],
      "metadata": {
        "id": "cEqtqAc8B14W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType,BooleanType,DateType, DoubleType\n",
        "df=df.withColumn(\"EstimatedSalary\",df.EstimatedSalary.cast(IntegerType()))"
      ],
      "metadata": {
        "id": "id5mi0hwIShF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType,BooleanType,DateType, DoubleType\n",
        "df=df.withColumn(\"Purchased\",df.Purchased.cast(IntegerType()))"
      ],
      "metadata": {
        "id": "tgH7M9pkIWT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "genderIndexer=StringIndexer(inputCol=\"Gender\", outputCol=\"GenderIndexed\")\n",
        "genderOneHotEncoder=OneHotEncoder(inputCols=[genderIndexer.getOutputCol()],outputCols=[\"GenderOHE\"])"
      ],
      "metadata": {
        "id": "uB42AjgLIXbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "vectorAssembler=VectorAssembler(inputCols=['GenderOHE', 'Age', 'EstimatedSalary'], outputCol=\"features\")"
      ],
      "metadata": {
        "id": "MZt_EhqQIZ_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)"
      ],
      "metadata": {
        "id": "BGJI5bHRIcuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "logistic_regression = LogisticRegression(featuresCol=\"scaledFeatures\", labelCol=\"Purchased\")"
      ],
      "metadata": {
        "id": "BxFyTJ7uIfEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df.randomSplit([0.8, 0.2], seed=13)"
      ],
      "metadata": {
        "id": "XsHM97igIiAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline=Pipeline(stages=[genderIndexer,genderOneHotEncoder,vectorAssembler,scaler,logistic_regression])\n",
        "model=pipeline.fit(train)"
      ],
      "metadata": {
        "id": "aj0SbrdBIkim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results=model.transform(test)"
      ],
      "metadata": {
        "id": "2F0JUSIkIon8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator=BinaryClassificationEvaluator(labelCol=\"Purchased\")\n",
        "accuracy = evaluator.evaluate(results)\n",
        "print (f\"Accuracy of the Model: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtfvf36wIrXU",
        "outputId": "c125f491-cc84-4e2c-b2a9-a013e2924e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Model: 0.9193313953488372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task **2**"
      ],
      "metadata": {
        "id": "jcRGcjQVI3wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.read.csv('/diabetes.csv',header=True,escape=\"\\\"\")"
      ],
      "metadata": {
        "id": "nzRMXOMkI8bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.classification import LinearSVCModel"
      ],
      "metadata": {
        "id": "wuRWh6G2JT5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "leVY3wdgJ4aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYY1todkK5Hc",
        "outputId": "fd2c7e7e-ffbb-4f0d-8ebc-63d59bf790b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Pregnancies: string, Glucose: string, BloodPressure: string, SkinThickness: string, Insulin: string, BMI: string, DiabetesPedigreeFunction: string, Age: string, Outcome: string]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType,BooleanType,DateType, DoubleType\n",
        "df1=df1.withColumn(\"Pregnancies\",df1.Pregnancies.cast(IntegerType()))\n",
        "df1=df1.withColumn(\"Glucose\",df1.Glucose.cast(IntegerType()))\n",
        "df1=df1.withColumn(\"BloodPressure\",df1.BloodPressure.cast(IntegerType()))\n",
        "df1=df1.withColumn(\"SkinThickness\",df1.SkinThickness.cast(IntegerType()))\n",
        "df1=df1.withColumn(\"Insulin\",df1.Insulin.cast(IntegerType()))\n",
        "df1=df1.withColumn(\"BMI\",df1.BMI.cast(IntegerType()))\n",
        "df1=df1.withColumn(\"DiabetesPedigreeFunction\",df1.DiabetesPedigreeFunction.cast(IntegerType()))\n",
        "df1=df1.withColumn(\"Age\",df1.Age.cast(IntegerType()))\n",
        "df1=df1.withColumn(\"Outcome\",df1.Outcome.cast(IntegerType()))"
      ],
      "metadata": {
        "id": "DSPlgKciLAV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorAssembler=VectorAssembler(inputCols=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'], outputCol=\"features\")"
      ],
      "metadata": {
        "id": "bzeKjiMjLzpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)"
      ],
      "metadata": {
        "id": "7sJ2Q8FANaW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.classification import LinearSVC"
      ],
      "metadata": {
        "id": "OHWImgg6Nsmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MultilayerPerceptronClassifier = MultilayerPerceptronClassifier(featuresCol=\"scaledFeatures\", labelCol=\"Outcome\",layers=[8, 5, 4, 2])"
      ],
      "metadata": {
        "id": "02l0HBTQNcNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LinearSVC = LinearSVC(featuresCol=\"scaledFeatures\", labelCol=\"Outcome\")"
      ],
      "metadata": {
        "id": "v_urz8yVNhvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df1.randomSplit([0.6, 0.4], seed=13)"
      ],
      "metadata": {
        "id": "6B-z9gJ8NvBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline=Pipeline(stages=[vectorAssembler,scaler,MultilayerPerceptronClassifier])\n",
        "model=pipeline.fit(train)"
      ],
      "metadata": {
        "id": "R55EQTfxNyDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results1=model.transform(test)"
      ],
      "metadata": {
        "id": "skHEb2l9PTit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator=MulticlassClassificationEvaluator(labelCol=\"Outcome\")\n",
        "accuracy = evaluator.evaluate(results1)\n",
        "print (f\"Accuracy of the Model: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew_c-n82P9Ah",
        "outputId": "4ec35e4d-e071-49f9-8aab-37f6d2abbab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Model: 0.7501561914282144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task-3**"
      ],
      "metadata": {
        "id": "-H4jzJQHOlKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark = SparkSession.builder.appName(\"ALSRecommendationSystem\").getOrCreate()\n",
        "\n",
        "ratings = spark.read.csv('/content/drive/MyDrive/Data Analytic Lab/rating.csv', header=True, inferSchema=True)\n",
        "\n",
        "ratings = ratings.withColumn(\"userId\", ratings[\"userId\"].cast(IntegerType())) \\\n",
        "                 .withColumn(\"movieId\", ratings[\"movieId\"].cast(IntegerType())) \\\n",
        "                 .withColumn(\"rating\", ratings[\"rating\"].cast(DoubleType()))\n",
        "\n",
        "\n",
        "(training, testing) = ratings.randomSplit([0.7, 0.3])\n",
        "\n",
        "als = ALS(itemCol=\"movieId\", userCol=\"userId\", rank=12, regParam=0.1, maxIter=20)\n",
        "\n",
        "\n",
        "model = als.fit(training)\n",
        "\n",
        "predictions = model.transform(testing)\n",
        "\n",
        "predictions = predictions.filter(predictions['prediction'].isNotNull())\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root-mean-square error = {rmse}\")\n"
      ],
      "metadata": {
        "id": "PwAjH-RrOjUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2aiSvY6BOjYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oASP759fOjbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcJlDhsVOje5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}